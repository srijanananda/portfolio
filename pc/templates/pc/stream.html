<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>PC Live Stream & Speech Recognition</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    #videoContainer {
      display: flex;
      gap: 20px;
      align-items: flex-start;
    }
    video {
      border: 1px solid #ccc;
      width: 480px;
      height: 360px;
      background: black;
    }
    #transcriptBox {
      width: 400px;
      height: 360px;
      border: 1px solid #ccc;
      padding: 10px;
      white-space: pre-wrap;
      overflow-y: auto;
      font-size: 16px;
      background: #f9f9f9;
    }
    button {
      margin-right: 10px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>

  <h1>PC Camera Live Stream & Speech-to-Text</h1>

  <div>
    <button id="connectBtn">Connect</button>
    <button id="startBtn" style="display:none;">Start</button>
    <button id="stopBtn" style="display:none;">Stop</button>
  </div>

  <div id="videoContainer" style="margin-top: 20px;">

    <video id="video" autoplay playsinline></video>

    <!-- Speech transcript box, initially hidden -->
    <div id="transcriptBox" style="display:none;">Listening...</div>

  </div>

 <script>
let video = document.getElementById('video');
let connectBtn = document.getElementById('connectBtn');
let startBtn = document.getElementById('startBtn');
let stopBtn = document.getElementById('stopBtn');
let transcriptBox = document.getElementById('transcriptBox');

let stream = null;
let recognizing = false;
let objectDetectionMode = false;
let speechRecognition;
let synth = window.speechSynthesis;

function speak(text) {
    if (synth.speaking) {
        synth.cancel();
    }
    const utter = new SpeechSynthesisUtterance(text);
    synth.speak(utter);
}

connectBtn.onclick = async () => {
    try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        video.srcObject = stream;
        startBtn.style.display = 'inline-block';
        connectBtn.disabled = true;
        transcriptBox.style.display = 'none'; // hide transcript initially
    } catch (err) {
        alert('Error accessing camera/mic: ' + err.message);
    }
};

startBtn.onclick = () => {
    startBtn.style.display = 'none';
    stopBtn.style.display = 'inline-block';
    transcriptBox.style.display = 'block';
    startRecognition();
};

stopBtn.onclick = () => {
    stopBtn.style.display = 'none';
    startBtn.style.display = 'inline-block';
    stopRecognition();
};

function setupSpeechRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        alert("Your browser does not support Speech Recognition API.");
        return;
    }
    speechRecognition = new SpeechRecognition();
    speechRecognition.continuous = true;
    speechRecognition.interimResults = false;
    speechRecognition.lang = 'en-US';

    speechRecognition.onresult = function(event) {
        const transcript = event.results[event.results.length - 1][0].transcript.trim();
        transcriptBox.textContent = transcript;

        if (!objectDetectionMode && transcript.toLowerCase().includes("detect object")) {
            speak("Object detection started.");
            objectDetectionMode = true;
            startObjectDetection();
        } else if (objectDetectionMode && transcript.toLowerCase().includes("stop detection")) {
            speak("Object detection stopped.");
            objectDetectionMode = false;
            stopObjectDetection();
        }
    };

    speechRecognition.onerror = function(event) {
        console.error("Speech recognition error", event.error);
    };

    speechRecognition.onend = function() {
        if (recognizing) {
            speechRecognition.start();
        }
    };
}

function startRecognition() {
    if (!speechRecognition) setupSpeechRecognition();
    recognizing = true;
    speechRecognition.start();
}

function stopRecognition() {
    recognizing = false;
    if (speechRecognition) speechRecognition.stop();
}

// Object detection variables
let detectionInterval;

function captureFrame() {
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    return canvas.toDataURL('image/jpeg');
}

function startObjectDetection() {
    detectionInterval = setInterval(async () => {
        if (!objectDetectionMode) return;

        const frameDataUrl = captureFrame();

        try {
            const response = await fetch('/pc/object_detect/', {
                method: 'POST',
                headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                body: 'image=' + encodeURIComponent(frameDataUrl),
            });
            const data = await response.json();

            if (data.object && data.object !== '') {
                console.log("Detected object:", data.object);
                speak(data.object);
            }
        } catch (e) {
            console.error('Error detecting object:', e);
        }
    }, 3000); // every 3 seconds to reduce load
}

function stopObjectDetection() {
    clearInterval(detectionInterval);
}

</script>

</body>
</html>
